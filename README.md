# LSTM-Based Next Word Prediction Model

A deep learning model built using TensorFlow and Keras that predicts the next word in a sequence of text using stacked LSTM layers.

---

## ðŸš€ Project Overview

This project demonstrates how to build a language model capable of predicting the next word given a partial sentence using Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) layers.

The entire pipeline includes:
- Text data preprocessing and tokenization
- Sequence padding and feature-label preparation
- Designing an LSTM-based sequential neural network
- Training using categorical cross-entropy loss
- Predicting next words based ona  trained model

---

## ðŸ”§ Key Features

- âœ… Text preprocessing using **Keras Tokenizer**
- âœ… Input sequence standardization via **padding**
- âœ… Deep Sequential Model with:
  - Embedding Layer
  - Two stacked LSTM layers
  - Dense Softmax Output Layer
- âœ… Loss Function: **Categorical Crossentropy**
- âœ… Optimizer: **Adam**
- âœ… Next word prediction loop implementation

---

